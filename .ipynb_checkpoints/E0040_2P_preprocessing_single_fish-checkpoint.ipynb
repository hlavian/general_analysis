{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from skimage import io as skio\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "from split_dataset import SplitDataset\n",
    "from fimpy.pipeline.alignment import align_2p_volume\n",
    "from fimpy.pipeline.roi_extraction import correlation_map\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = Path(r\"\\\\FUNES\\Shared\\experiments\\E0040_motions_cardinal\\v13_cw_ccw\\2p\\habenula\\fixed\")\n",
    "master = Path(r\"\\\\Funes\\Shared\\experiments\\E0040_motions_cardinal\\v13_cw_ccw\\2p\\rf\\fixed\")\n",
    "master = Path(r\"\\\\FUNES\\Shared\\experiments\\E0044_spontaneous\\gad1b\\2p_anatomy\\gcamp6s\")\n",
    "#master = Path(r\"\\\\Funes\\Shared\\experiments\\E0044_spontaneous\\itpr1b\\cerebellum\")\n",
    "#master = Path(r\"\\\\FUNES\\Shared\\experiments\\E0020_random_coherences\\v30_two_options_with_multiple_forward_tests_embedded_ls\\2p\\gad1b-6s\\v33\\new\")\n",
    "\n",
    "master = Path(r\"\\\\Funes\\Shared\\experiments\\E0040_motions_cardinal\\v13_cw_ccw\\2p\\ipn\\gad1b\")\n",
    "all_fish = list(master.glob(\"*f[0-9]*\"))\n",
    "fish_dir = all_fish[0]\n",
    "print(fish_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = \"anatomy\\original\"\n",
    "source_dir = \"original\"\n",
    "\n",
    "frames_per_plane = None\n",
    "aligned_dir = \"aligned\"\n",
    "force_realign = False\n",
    "force_remake_tifs = False\n",
    "force_remake_corr = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flammkuchen as fl\n",
    "import json\n",
    "inc_factor = 2**12\n",
    "\n",
    "metadata_file_stack = fish_dir / \"original_o/stack_metadata.json\"\n",
    "with open(str(metadata_file_stack), \"r\") as fr:\n",
    "    stack_param = json.load(fr)\n",
    "n_z, nx, ny = stack_param[\"shape_full\"][1:4]\n",
    "stack = SplitDataset(fish_dir / \"original_o/\")\n",
    "print(n_z)\n",
    "for i in range(n_z):\n",
    "    if i < 10:\n",
    "        file_name = '000' + str(i) + '.h5'\n",
    "    else:\n",
    "        file_name = '00' + str(i) + '.h5'\n",
    "    print(file_name)\n",
    "\n",
    "    data_in = stack[:, i, :, :]\n",
    "    print(np.max(data_in), np.min(data_in), np.mean(data_in))\n",
    "\n",
    "    data_out = (data_in + 0.05) * inc_factor\n",
    "    print(np.max(data_out), np.min(data_out), np.mean(data_out))\n",
    "    print(np.percentile(data_in, 99.999))\n",
    "\n",
    "    data_out = data_out.astype(np.uint16)\n",
    "    data_out = np.expand_dims(data_out, 1)\n",
    "    data_out_folder = str(fish_dir / \"original\" / file_name)\n",
    "\n",
    "    fl.save(data_out_folder, {\"stack_4D\": data_out}, compression=\"blosc\")\n",
    "    data_in = 0\n",
    "    data_out = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds = SplitDataset(fish_dir / \"original\")\n",
    "#stack = ds[:, :, :, :]\n",
    "#print(np.shape(stack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "align_2p_volume(SplitDataset(fish_dir / source_dir), output_dir=str(fish_dir), across_planes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = SplitDataset(fish_dir / \"aligned\")\n",
    "stack = ds[:, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stack.max(), stack.mean())\n",
    "mean = stack.mean(0)\n",
    "print(np.shape(mean))\n",
    "skio.imsave(str(fish_dir / \"anatomy.tif\"), mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = 0\n",
    "stack = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = SplitDataset(fish_dir / source_dir)\n",
    "stack = ds[:, :, :, :]\n",
    "print(stack.max(), stack.mean())\n",
    "mean = stack.mean(0)\n",
    "print(np.shape(mean))\n",
    "skio.imsave(str(fish_dir / \"anatomy_original.tif\"), mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = skio.imread(str(fish_dir /  \"anatomy.tif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "align_2p_volume(SplitDataset(fish_dir / source_dir), output_dir=str(fish_dir), reference=mean, across_planes=False)\n",
    "ds = SplitDataset(fish_dir / \"aligned\")\n",
    "stack = ds[:, :, :, :]\n",
    "print(stack.max(), stack.mean())\n",
    "mean = stack.mean(0)\n",
    "print(np.shape(mean))\n",
    "skio.imsave(str(fish_dir / \"anatomy2.tif\"), mean.astype(np.uint16))\n",
    "ds = 0\n",
    "stack = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#anatomy = skio.imread(str(fish_dir / \"anatomy1.tif\"))\n",
    "#anatomy2 = anatomy.T\n",
    "#print(np.shape(anatomy2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_realign = True\n",
    "force_remake_tifs = False \n",
    "\n",
    "for i in range(2, 5):\n",
    "    \n",
    "    anatomy_file = \"anatomy\" + str(i) + \".tif\"\n",
    "    \n",
    "    # Create anatomy tif file:\n",
    "    if not (fish_dir / anatomy_file).exists() or force_remake_tifs:\n",
    "        print(\"Saving anatomy...\")\n",
    "        ds = SplitDataset(fish_dir / \"aligned\")\n",
    "        stack = ds[:, :, :, :]\n",
    "        print(stack.max())\n",
    "        mean = stack.mean(0)\n",
    "\n",
    "        skio.imsave(str(fish_dir / anatomy_file), mean.astype(np.uint16))\n",
    "        stack = 0\n",
    "        \n",
    "    # Align:\n",
    "    if not (fish_dir / aligned_dir).exists() or force_realign:\n",
    "        print(\"Aligning...\")\n",
    "\n",
    "        anatomy = skio.imread(str(fish_dir / anatomy_file))\n",
    "        #anatomy = anatomy.T\n",
    "        align_2p_volume(SplitDataset(fish_dir / source_dir), output_dir=str(fish_dir), reference=anatomy, across_planes=False)\n",
    "    else:\n",
    "        print(\"Already aligned\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (fish_dir / \"corrmap.tif\").exists():\n",
    "    print(\"Saving correlation map\")\n",
    "    ds = SplitDataset(fish_dir / \"aligned\")\n",
    "    corr_map = correlation_map(ds)[:, :, :]\n",
    "    skio.imsave(str(fish_dir / \"corrmap.tif\"), corr_map.astype(np.float))\n",
    "    \n",
    "ds = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flammkuchen as fl\n",
    "from fimpy.pipeline.roi_extraction import extract_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting traces: \n",
    "# master = Path(r\"C:\\Users\\lavian\\Desktop\\data\\e0040_V13\")\n",
    "master = Path(r\"\\\\Funes\\Shared\\experiments\\E0040_motions_cardinal\\v13_cw_ccw\\2p\\habenula\\fixed\")\n",
    "master = Path(r\"C:\\Users\\lavian\\Desktop\\data\\e0040_V13\\rf\\fixed\")\n",
    "all_fish = list(master.glob(\"*f[0-9]*\"))\n",
    "fish_dir = all_fish[5]\n",
    "print(fish_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_rois = str(fish_dir/'merged_rois.h5')\n",
    "dir_aligned = str(fish_dir / \"aligned\")\n",
    "aligned = SplitDataset(dir_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois_arr = fl.load(dir_rois)['stack'] \n",
    "rois_arr = rois_arr.astype(int) - 1\n",
    "traces = extract_traces(aligned, rois_arr)\n",
    "np.shape(rois_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir_rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

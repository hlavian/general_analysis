{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of lightsheet data (fimpy)\n",
    "#### This notebook is used for preprocessing of lightsheet data using fimpy. This is the first stage of analysis follwing acquisition of the data. \n",
    "#### Use this notebook for alignment, anatomy, correlation map and downsampling of all datasets in the master folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import glob\n",
    "from skimage import io as skio\n",
    "\n",
    "from split_dataset import SplitDataset\n",
    "from fimpy.pipeline.alignment import align_volumes_with_filtering\n",
    "from fimpy.pipeline.roi_extraction import correlation_map, extract_traces, grow_rois\n",
    "from fimpy.pipeline.common import run_in_blocks\n",
    "from fimpy.pipeline.general import downsample\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = Path(r\"\\\\Funes\\Shared\\experiments\\E0044_spontaneous\\gad1b\\ls\\e0044_v00\")\n",
    "master = Path(r\"\\\\Funes\\Shared\\experiments\\E0020_random_coherences\\v30_two_options_with_multiple_forward_tests_embedded_ls\\lightsheet\\v34\")\n",
    "master = Path(r\"\\\\Funes\\Shared\\experiments\\E0040_motions_cardinal\\v13_cw_ccw\\ls_fixed\\new\")\n",
    "stack_path = Path(r\"\\\\FUNES\\Shared\\experiments\\E0040_motions_cardinal\\v17_2d_vr\\210506_f4ipn_2dvr\")\n",
    "master = Path(r\"\\\\Funes\\Shared\\experiments\\E0040_motions_cardinal\\v13_cw_ccw\\ls_fixed\\spont_plus_v13\\new\")\n",
    "master = Path(r\"\\\\Funes\\Shared\\experiments\\E0040_motions_cardinal\\v21\")\n",
    "\n",
    "master = Path(r\"\\\\Funes\\Shared\\experiments\\E0020_random_coherences\\v35_two_options_forward_ol\\h2b\\new\")\n",
    "list(master.glob(\"*f*\"))\n",
    "fish_list =list(master.glob(\"*f*\"))\n",
    "fish_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alignment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_realign = False \n",
    "fish_list = list(master.glob(\"*f[0-9]*\"))\n",
    "#fish_list = [stack_path]\n",
    "for f in fish_list:\n",
    "    print(f)\n",
    "    if not (f / \"aligned\").exists() or force_realign:\n",
    "        print(\"Aligning...\")\n",
    "        loaded = SplitDataset(f / \"original\")\n",
    "        aligned = align_volumes_with_filtering(loaded, ref_window_halfsize=30, prefilter_sigma=3.3, block_size=120, verbose=True)\n",
    "    else:\n",
    "        print(\"Already aligned\")\n",
    "    \n",
    "    loaded = 0\n",
    "    aligned = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anatomy and correlation maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_remake_tifs = True\n",
    "force_remake_corr = False\n",
    "time_lims = (500, 700)\n",
    "for f in fish_list:\n",
    "    print(f)\n",
    "    ds = 0\n",
    "    mean=0\n",
    "    corr_map = 9\n",
    "    if not (f / \"anatomy.tif\").exists() or force_remake_tifs:\n",
    "        print(\"Saving anatomy\")\n",
    "        ds = SplitDataset(f / \"original\")\n",
    "        mean = ds[time_lims[0]:time_lims[1]].mean(0)\n",
    "        skio.imsave(str(f / \"anatomy.tif\"), mean.astype(np.uint16))\n",
    "        \n",
    "    if not (f / \"corrmap.tif\").exists() or force_remake_tifs:\n",
    "        print(\"Saving correlation map\")\n",
    "        ds = SplitDataset(f / \"aligned\")\n",
    "        corr_map = correlation_map(ds, time_lims=time_lims)[:, :, :]\n",
    "        skio.imsave(str(f / \"corrmap.tif\"), corr_map.astype(np.float))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "second alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in list(master.glob(\"*f[0-9]*\")):\n",
    "    print(f)\n",
    "    loaded = SplitDataset(f / \"original\")\n",
    "    aligned = align_volumes_with_filtering(loaded, ref_window_halfsize=30, fft_reference, prefilter_sigma=3.3, block_size=120, verbose=True)\n",
    "    loaded = 0\n",
    "    aligned = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in list(master.glob(\"*f[0-9]*\")):\n",
    "    print(f)\n",
    "    if not (f / \"downsampled\").exists() :\n",
    "        loaded = SplitDataset(f / \"aligned\")\n",
    "        aligned = downsample(loaded, output_dir=f, downsampling=(1,1,10,10))\n",
    "        loaded = 0\n",
    "        aligned = 0\n",
    "    else:\n",
    "        print(\"already downsampled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in list(master.glob(\"*f[0-9]*\")):\n",
    "    print(f)\n",
    "    loaded = SplitDataset(f / \"correlation_map\")\n",
    "    corr_map = downsample(loaded, output_dir=f / \"downsampled\" / \"corrmap\", downsampling=(1,10,10))\n",
    "    loaded = 0\n",
    "    aligned = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

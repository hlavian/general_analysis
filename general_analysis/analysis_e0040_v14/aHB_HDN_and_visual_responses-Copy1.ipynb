{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-petersburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-forty",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import flammkuchen as fl\n",
    "import pandas as pd\n",
    "import tifffile as tiff\n",
    "\n",
    "from fimpylab import LightsheetExperiment\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "sns.set(style=\"ticks\", palette=\"deep\")\n",
    "cols = sns.color_palette()\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from lotr.utils import zscore\n",
    "from lotr.pca import pca_and_phase, get_fictive_heading, fictive_heading_and_fit, \\\n",
    "        fit_phase_neurons,qap_sorting_and_phase\n",
    "from circle_fit import hyper_fit\n",
    "from lotr.experiment_class import LotrExperiment\n",
    "import json\n",
    "\n",
    "from lotr.plotting.color_utils import get_n_colors\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-effects",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(r\"\\\\Funes\\Shared\\experiments\\E0071_lotr\\full_ring\\210314_f1\\210314_f1_natmov\")\n",
    "master =  Path(r\"\\\\Funes\\Shared\\experiments\\E0071_lotr\\full_ring\")\n",
    "files = list(master.glob(\"*/*_f*\"))\n",
    "path = files[71] \n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-scholar",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "traces = fl.load(path / \"filtered_traces.h5\", \"/detr\").T\n",
    "try:\n",
    "    selected = fl.load(path / \"selected.h5\")\n",
    "except:\n",
    "    print(\"no selected\")\n",
    "\n",
    "reg_df = fl.load(path / \"motor_regressors.h5\")\n",
    "cc_motor = reg_df[\"all_bias_abs\"].values\n",
    "cc_motor_integr = reg_df[\"all_bias_abs_dfdt\"].values\n",
    "try:\n",
    "    coords = fl.load(path / \"data_from_suite2p_unfiltered.h5\", \"/coords\")\n",
    "    anat = fl.load(path / \"data_from_suite2p_unfiltered.h5\", \"/anatomy_stack\")\n",
    "except:\n",
    "    coords = fl.load(path / \"data_from_suite2p_cells.h5\", \"/coords\")\n",
    "    anat = fl.load(path / \"data_from_suite2p_cells.h5\", \"/anatomy_stack\")\n",
    "\n",
    "df = fl.load(path / \"bouts_df.h5\")# exp.get_bout_properties()\n",
    "exp = LotrExperiment(path)\n",
    "fn = int(exp.fn)\n",
    "beh_df = exp.behavior_log\n",
    "\n",
    "t_start_s = 150\n",
    "t_lims = [150, -50]\n",
    "t_slice = slice(*t_lims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-conflict",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(traces))\n",
    "print(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-research",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_log = exp.stimulus_log\n",
    "beh_log = exp.behavior_log\n",
    "stim_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-information",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    theta = np.asarray(stim_log['bg_theta'])\n",
    "except:\n",
    "    theta1 = np.asarray(stim_log['open_loop_theta'])\n",
    "    theta1[np.where(np.isnan(theta1))[0]] = 0\n",
    "    theta2 = np.asarray(stim_log['closed_loop_theta'])\n",
    "    theta2[np.where(np.isnan(theta2))[0]] = 0\n",
    "    theta = theta1 + theta2\n",
    "#theta = np.asarray(stim_log['cl2D_vel'])\n",
    "stim_t = np.asarray(stim_log.t)\n",
    "\n",
    "theta_wrapped = np.mod(theta, np.pi * 2) - np.pi\n",
    "theta_diff = np.zeros_like(theta)\n",
    "theta_diff[1:] = np.diff(theta)\n",
    "theta_diff[theta_diff < -0.5] = 0\n",
    "theta_diff *= 50\n",
    "\n",
    "pos_theta = np.copy(theta_diff)\n",
    "pos_theta[pos_theta < 0] = 0\n",
    "\n",
    "neg_theta = np.copy(theta_diff)\n",
    "neg_theta[neg_theta > 0] = 0\n",
    "\n",
    "theta_off = np.zeros_like(theta)\n",
    "theta_off[1:] = np.diff(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-radiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(stim_t, (theta / 5)+ 5)\n",
    "ax.plot(stim_t, theta_wrapped)\n",
    "ax.plot(stim_t, (theta_diff)-10)\n",
    "ax.plot(beh_log.t, beh_log.tail_sum - 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-genesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = exp.fn\n",
    "print(fs)\n",
    "dt_imaging = 1 / fs\n",
    "int_fact = 200\n",
    "t_imaging = np.arange(traces.shape[1])/fs\n",
    "num_traces, len_rec = np.shape(traces)\n",
    "\n",
    "# generating regressors\n",
    "from lotr.default_vals import REGRESSOR_TAU_S, TURN_BIAS\n",
    "\n",
    "tau_fs = REGRESSOR_TAU_S * fn\n",
    "kernel = np.exp(-np.arange(1000) / tau_fs)\n",
    "t_imaging_int = np.arange(traces.shape[1]*int_fact)*dt_imaging/int_fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-university",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_int = interp1d(stim_log.t, theta, bounds_error=False, fill_value=0)(t_imaging_int)\n",
    "theta_reg = signal.decimate(theta_int, int_fact, ftype=\"fir\")\n",
    "theta_reg_conv = np.convolve(theta_reg, kernel)[:np.shape(traces)[1]]\n",
    "\n",
    "theta_wrp_int = interp1d(stim_log.t, theta_wrapped, bounds_error=False, fill_value=0)(t_imaging_int)\n",
    "theta_wrp_reg = signal.decimate(theta_wrp_int, int_fact, ftype=\"fir\")\n",
    "theta_wrp_conv = np.convolve(theta_wrp_reg, kernel)[:np.shape(traces)[1]]\n",
    "\n",
    "theta_diff_int = interp1d(stim_log.t, theta_diff, bounds_error=False, fill_value=0)(t_imaging_int)\n",
    "theta_diff_reg = signal.decimate(theta_diff_int, int_fact, ftype=\"fir\")\n",
    "theta_diff_conv = np.convolve(theta_diff_reg, kernel)[:np.shape(traces)[1]]\n",
    "\n",
    "theta_off_int = interp1d(stim_log.t, theta_off, bounds_error=False, fill_value=0)(t_imaging_int)\n",
    "theta_off_reg = signal.decimate(theta_off_int, int_fact, ftype=\"fir\") * -1\n",
    "theta_off_conv = np.convolve(theta_off_reg, kernel)[:np.shape(traces)[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-premium",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,1, figsize=(6, 7))\n",
    "stim_t_conv = np.arange(np.shape(theta_reg_conv)[0]) / 5\n",
    "ax[0].plot(stim_t_conv, theta_reg_conv / 5 + 150)\n",
    "ax[0].plot(stim_t_conv, theta_wrp_conv)\n",
    "ax[0].plot(stim_t_conv, theta_diff_conv + 80)\n",
    "ax[0].plot(beh_log.t, beh_log.tail_sum*10 - 80)\n",
    "ax[0].plot(stim_t_conv, theta_off_conv/5 - 200)\n",
    "ax[0].set_xlim(0, stim_t_conv[-1])\n",
    "\n",
    "ax[1].imshow(traces, vmin=-1, vmax=2, extent=[0, 1500, 0, 500])\n",
    "ax[0].axis('off')\n",
    "ax[1].axis('off')\n",
    "\n",
    "ax[2].imshow(traces[selected], vmin=-1, vmax=2, extent=[0, 1500, 0, 500])\n",
    "ax[2].axis('off')\n",
    "file_name = 'theta_regressors.jpg'\n",
    "fig.savefig(path / file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-canon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-criterion",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_traces = np.dot(traces, theta_reg_conv) - num_traces * np.mean(traces, 1) * np.mean(theta_reg_conv)\n",
    "theta_traces /= (traces.shape[1] - 1) * np.std(traces, 1) * np.std(theta_reg_conv)\n",
    "\n",
    "theta_wrp_traces = np.dot(traces, theta_wrp_conv) - num_traces * np.mean(traces, 1) * np.mean(theta_wrp_conv)\n",
    "theta_wrp_traces /= (traces.shape[1] - 1) * np.std(traces, 1) * np.std(theta_wrp_conv)\n",
    "\n",
    "theta_diff_traces = np.dot(traces, theta_diff_conv) - num_traces * np.mean(traces, 1) * np.mean(theta_diff_conv)\n",
    "theta_diff_traces /= (traces.shape[1] - 1) * np.std(traces, 1) * np.std(theta_diff_conv)\n",
    "\n",
    "theta_off_traces = np.dot(traces, theta_off_conv) - num_traces * np.mean(traces, 1) * np.mean(theta_off_conv)\n",
    "theta_off_traces /= (traces.shape[1] - 1) * np.std(traces, 1) * np.std(theta_off_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-instrumentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_values = {\n",
    "    'theta_reg': theta_traces,\n",
    "    'theta_wrp_reg': theta_wrp_traces,\n",
    "    'theta_diff_reg': theta_diff_traces,\n",
    "    'theta_off_reg': theta_off_traces,\n",
    "    }\n",
    "fl.save(str(path / 'stimulus_regression_values.h5'), reg_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-forward",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_anatomy2, ax_anatomy2 = plt.subplots(2, 3, figsize=(7, 6), sharex=True, sharey=True)\n",
    "\n",
    "ax_anatomy2[0,0].scatter(coords[:, 1], coords[:, 2], c=theta_wrp_traces, cmap='coolwarm', s=3, vmin=-1, vmax=1)\n",
    "ax_anatomy2[0,0].axis('off')\n",
    "ax_anatomy2[0,0].set_title('Theta wrapped')\n",
    "\n",
    "ax_anatomy2[0,1].scatter(coords[:, 1], coords[:, 2], c=theta_diff_traces, cmap='coolwarm', s=3, vmin=-1, vmax=1)\n",
    "ax_anatomy2[0,1].axis('off')\n",
    "ax_anatomy2[0,1].set_title('Theta diff')\n",
    "\n",
    "ax_anatomy2[0,2].scatter(coords[:, 1], coords[:, 2], c=theta_off_traces, cmap='coolwarm', s=3, vmin=-1, vmax=1)\n",
    "ax_anatomy2[0,2].axis('off')\n",
    "ax_anatomy2[0,2].set_title('Theta off')\n",
    "\n",
    "ax_anatomy2[1,0].scatter(coords[selected, 1], coords[selected, 2], c=theta_wrp_traces[selected], cmap='coolwarm', s=3, vmin=-1, vmax=1)\n",
    "ax_anatomy2[1,0].axis('off')\n",
    "\n",
    "ax_anatomy2[1,1].scatter(coords[selected, 1], coords[selected, 2], c=theta_diff_traces[selected], cmap='coolwarm', s=3, vmin=-1, vmax=1)\n",
    "ax_anatomy2[1,1].axis('off')\n",
    "\n",
    "ax_anatomy2[1,2].scatter(coords[selected, 1], coords[selected, 2], c=theta_off_traces[selected], cmap='coolwarm', s=3, vmin=-1, vmax=1)\n",
    "ax_anatomy2[1,2].axis('off')\n",
    "\n",
    "file_name = 'theta_regressors_rois.jpg'\n",
    "fig_anatomy2.savefig(path / file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-glance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-jesus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making one big figure:\n",
    "from lotr.default_vals import REGRESSOR_TAU_S, TURN_BIAS\n",
    "master =  Path(r\"\\\\Funes\\Shared\\experiments\\E0071_lotr\\full_ring\")\n",
    "files = list(master.glob(\"*/*_f*_natmov*\"))\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-stylus",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_anatomy2, ax_anatomy2 = plt.subplots(7, 6, figsize=(10, 10), sharex=True, sharey=True)\n",
    "\n",
    "count = 0\n",
    "for i in range(len(files)):\n",
    "    path = files[i]\n",
    "    traces = fl.load(path / \"filtered_traces.h5\", \"/detr\").T\n",
    "    \n",
    "    try:\n",
    "        with open(next(path.glob(\"*metadata.json\"))) as gg:\n",
    "            metadata = json.load(gg)\n",
    "        fish_id = metadata['general']['fish_id']\n",
    "    except:\n",
    "        fish_id = \"\"\n",
    "    print(fish_id)\n",
    "    try:\n",
    "        selected = fl.load(path / \"selected.h5\")\n",
    "        \n",
    "        reg_df = fl.load(path / \"motor_regressors.h5\")\n",
    "        cc_motor = reg_df[\"all_bias_abs\"].values\n",
    "        cc_motor_integr = reg_df[\"all_bias_abs_dfdt\"].values\n",
    "        try:\n",
    "            coords = fl.load(path / \"data_from_suite2p_unfiltered.h5\", \"/coords\")\n",
    "            anat = fl.load(path / \"data_from_suite2p_unfiltered.h5\", \"/anatomy_stack\")\n",
    "        except:\n",
    "            coords = fl.load(path / \"data_from_suite2p_cells.h5\", \"/coords\")\n",
    "            anat = fl.load(path / \"data_from_suite2p_cells.h5\", \"/anatomy_stack\")\n",
    "\n",
    "        df = fl.load(path / \"bouts_df.h5\")# exp.get_bout_properties()\n",
    "        exp = LotrExperiment(path)\n",
    "        fn = int(exp.fn)\n",
    "\n",
    "        t_start_s = 150\n",
    "        t_lims = [150, -50]\n",
    "        t_slice = slice(*t_lims)\n",
    "        \n",
    "        stim_log = exp.stimulus_log\n",
    "        beh_log = exp.behavior_log\n",
    "    \n",
    "        try:\n",
    "            theta = np.asarray(stim_log['bg_theta'])\n",
    "        except:\n",
    "            theta1 = np.asarray(stim_log['open_loop_theta'])\n",
    "            theta1[np.where(np.isnan(theta1))[0]] = 0\n",
    "            theta2 = np.asarray(stim_log['closed_loop_theta'])\n",
    "            theta2[np.where(np.isnan(theta2))[0]] = 0\n",
    "            theta = theta1 + theta2\n",
    "        #theta = np.asarray(stim_log['cl2D_vel'])\n",
    "        stim_t = np.asarray(stim_log.t)\n",
    "\n",
    "        theta_wrapped = np.mod(theta, np.pi * 2) - np.pi\n",
    "        theta_diff = np.zeros_like(theta)\n",
    "        theta_diff[1:] = np.diff(theta)\n",
    "        theta_diff[theta_diff < -0.5] = 0\n",
    "        theta_diff *= 50\n",
    "\n",
    "        pos_theta = np.copy(theta_diff)\n",
    "        pos_theta[pos_theta < 0] = 0\n",
    "\n",
    "        neg_theta = np.copy(theta_diff)\n",
    "        neg_theta[neg_theta > 0] = 0\n",
    "\n",
    "        theta_off = np.zeros_like(theta)\n",
    "        theta_off[1:] = np.diff(theta)\n",
    "        \n",
    "        fs = exp.fn\n",
    "        dt_imaging = 1 / fs\n",
    "        int_fact = 200\n",
    "        t_imaging = np.arange(traces.shape[1])/fs\n",
    "        num_traces, len_rec = np.shape(traces)\n",
    "\n",
    "        # generating regressors\n",
    "        tau_fs = REGRESSOR_TAU_S * fn\n",
    "        kernel = np.exp(-np.arange(1000) / tau_fs)\n",
    "        t_imaging_int = np.arange(traces.shape[1]*int_fact)*dt_imaging/int_fact\n",
    "    \n",
    "        theta_int = interp1d(stim_log.t, theta, bounds_error=False, fill_value=0)(t_imaging_int)\n",
    "        theta_reg = signal.decimate(theta_int, int_fact, ftype=\"fir\")\n",
    "        theta_reg_conv = np.convolve(theta_reg, kernel)[:np.shape(traces)[1]]\n",
    "\n",
    "        theta_wrp_int = interp1d(stim_log.t, theta_wrapped, bounds_error=False, fill_value=0)(t_imaging_int)\n",
    "        theta_wrp_reg = signal.decimate(theta_wrp_int, int_fact, ftype=\"fir\")\n",
    "        theta_wrp_conv = np.convolve(theta_wrp_reg, kernel)[:np.shape(traces)[1]]\n",
    "\n",
    "        theta_diff_int = interp1d(stim_log.t, theta_diff, bounds_error=False, fill_value=0)(t_imaging_int)\n",
    "        theta_diff_reg = signal.decimate(theta_diff_int, int_fact, ftype=\"fir\")\n",
    "        theta_diff_conv = np.convolve(theta_diff_reg, kernel)[:np.shape(traces)[1]]\n",
    "\n",
    "        theta_off_int = interp1d(stim_log.t, theta_off, bounds_error=False, fill_value=0)(t_imaging_int)\n",
    "        theta_off_reg = signal.decimate(theta_off_int, int_fact, ftype=\"fir\") * -1\n",
    "        theta_off_conv = np.convolve(theta_off_reg, kernel)[:np.shape(traces)[1]]\n",
    "        \n",
    "        \n",
    "        fig, ax = plt.subplots(3,1, figsize=(6, 7))\n",
    "        stim_t_conv = np.arange(np.shape(theta_reg_conv)[0]) / 5\n",
    "        ax[0].plot(stim_t_conv, theta_reg_conv / 5 + 150)\n",
    "        ax[0].plot(stim_t_conv, theta_wrp_conv)\n",
    "        ax[0].plot(stim_t_conv, theta_diff_conv + 80)\n",
    "        ax[0].plot(beh_log.t, beh_log.tail_sum*10 - 80)\n",
    "        ax[0].plot(stim_t_conv, theta_off_conv/5 - 200)\n",
    "        ax[0].set_xlim(0, stim_t_conv[-1])\n",
    "\n",
    "        ax[1].imshow(traces, vmin=-1, vmax=2, extent=[0, 1500, 0, 500])\n",
    "        ax[0].axis('off')\n",
    "        ax[1].axis('off')\n",
    "\n",
    "        ax[2].imshow(traces[selected], vmin=-1, vmax=2, extent=[0, 1500, 0, 500])\n",
    "        ax[2].axis('off')\n",
    "        file_name = 'theta_regressors.jpg'\n",
    "        fig.savefig(path / file_name)\n",
    "\n",
    "        theta_traces = np.dot(traces, theta_reg_conv) - num_traces * np.mean(traces, 1) * np.mean(theta_reg_conv)\n",
    "        theta_traces /= (traces.shape[1] - 1) * np.std(traces, 1) * np.std(theta_reg_conv)\n",
    "\n",
    "        theta_wrp_traces = np.dot(traces, theta_wrp_conv) - num_traces * np.mean(traces, 1) * np.mean(theta_wrp_conv)\n",
    "        theta_wrp_traces /= (traces.shape[1] - 1) * np.std(traces, 1) * np.std(theta_wrp_conv)\n",
    "\n",
    "        theta_diff_traces = np.dot(traces, theta_diff_conv) - num_traces * np.mean(traces, 1) * np.mean(theta_diff_conv)\n",
    "        theta_diff_traces /= (traces.shape[1] - 1) * np.std(traces, 1) * np.std(theta_diff_conv)\n",
    "\n",
    "        theta_off_traces = np.dot(traces, theta_off_conv) - num_traces * np.mean(traces, 1) * np.mean(theta_diff_conv)\n",
    "        theta_off_traces /= (traces.shape[1] - 1) * np.std(traces, 1) * np.std(theta_off_conv)\n",
    "        \n",
    "        \n",
    "\n",
    "        ax_anatomy2[i-count,0].scatter(coords[:, 1], coords[:, 2], c=theta_wrp_traces, cmap='coolwarm', s=3, vmin=-1, vmax=1)\n",
    "        #ax_anatomy2[i-count,0].axis('off')\n",
    "        ax_anatomy2[i-count,0].spines['right'].set_visible(False)\n",
    "        ax_anatomy2[i-count,0].spines['top'].set_visible(False)\n",
    "        ax_anatomy2[i-count,0].spines['left'].set_visible(False)\n",
    "        ax_anatomy2[i-count,0].spines['bottom'].set_visible(False)\n",
    "        ax_anatomy2[i-count,0].set_xticks([])\n",
    "        ax_anatomy2[i-count,0].set_yticks([])\n",
    "        ax_anatomy2[i-count,0].set_ylabel(fish_id)\n",
    "        \n",
    "        ax_anatomy2[i-count,1].scatter(coords[:, 1], coords[:, 2], c=theta_diff_traces, cmap='coolwarm', s=3, vmin=-1, vmax=1)\n",
    "        ax_anatomy2[i-count,1].axis('off')\n",
    "\n",
    "        ax_anatomy2[i-count,2].scatter(coords[:, 1], coords[:, 2], c=theta_off_traces, cmap='coolwarm', s=3, vmin=-1, vmax=1)\n",
    "        ax_anatomy2[i-count,2].axis('off')\n",
    "        \n",
    "        ax_anatomy2[i-count,3].scatter(coords[selected, 1], coords[selected, 2], c=theta_wrp_traces[selected], cmap='coolwarm', s=3, vmin=-1, vmax=1)\n",
    "        ax_anatomy2[i-count,3].axis('off')\n",
    "        \n",
    "        ax_anatomy2[i-count,4].scatter(coords[selected, 1], coords[selected, 2], c=theta_diff_traces[selected], cmap='coolwarm', s=3, vmin=-1, vmax=1)\n",
    "        ax_anatomy2[i-count,4].axis('off')\n",
    "\n",
    "        ax_anatomy2[i-count,5].scatter(coords[selected, 1], coords[selected, 2], c=theta_off_traces[selected], cmap='coolwarm', s=3, vmin=-1, vmax=1)\n",
    "        ax_anatomy2[i-count,5].axis('off')\n",
    "\n",
    "        \n",
    "    except:\n",
    "        print(\"no selected\")\n",
    "        count += 1\n",
    "        \n",
    "ax_anatomy2[0,0].set_title('Theta position')\n",
    "ax_anatomy2[0,1].set_title('Theta diff')\n",
    "ax_anatomy2[0,2].set_title('Theta off')\n",
    "\n",
    "ax_anatomy2[0,3].set_title('Theta position - selected')\n",
    "ax_anatomy2[0,4].set_title('Theta diff - selected')\n",
    "ax_anatomy2[0,5].set_title('Theta off - selected')\n",
    "\n",
    "file_name = 'theta_regressors_rois_natmov.jpg'\n",
    "fig_anatomy2.savefig(master / file_name, dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-grammar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making one big figure:\n",
    "master =  Path(r\"\\\\Funes\\Shared\\experiments\\E0071_lotr\\full_ring\")\n",
    "files = list(master.glob(\"*/*_f*_clol*\"))\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-taiwan",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_anatomy2, ax_anatomy2 = plt.subplots(7, 6, figsize=(10, 10), sharex=True, sharey=True)\n",
    "fig_anatomy1, ax_anatomy1 = plt.subplots(8, 1, figsize=(6, 12))\n",
    "\n",
    "\n",
    "count = 0\n",
    "for i in range(len(files)):\n",
    "    path = files[i]\n",
    "    traces = fl.load(path / \"filtered_traces.h5\", \"/detr\").T\n",
    "    \n",
    "    try:\n",
    "        with open(next(path.glob(\"*metadata.json\"))) as gg:\n",
    "            metadata = json.load(gg)\n",
    "        fish_id = metadata['general']['fish_id']\n",
    "    except:\n",
    "        fish_id = \"\"\n",
    "    print(fish_id)\n",
    "    \n",
    "    try:\n",
    "        selected = fl.load(path / \"selected.h5\")\n",
    "        \n",
    "        reg_df = fl.load(path / \"motor_regressors.h5\")\n",
    "        cc_motor = reg_df[\"all_bias_abs\"].values\n",
    "        cc_motor_integr = reg_df[\"all_bias_abs_dfdt\"].values\n",
    "        try:\n",
    "            coords = fl.load(path / \"data_from_suite2p_unfiltered.h5\", \"/coords\")\n",
    "            anat = fl.load(path / \"data_from_suite2p_unfiltered.h5\", \"/anatomy_stack\")\n",
    "        except:\n",
    "            coords = fl.load(path / \"data_from_suite2p_cells.h5\", \"/coords\")\n",
    "            anat = fl.load(path / \"data_from_suite2p_cells.h5\", \"/anatomy_stack\")\n",
    "\n",
    "        df = fl.load(path / \"bouts_df.h5\")# exp.get_bout_properties()\n",
    "        exp = LotrExperiment(path)\n",
    "        fn = int(exp.fn)\n",
    "\n",
    "        t_start_s = 150\n",
    "        t_lims = [150, -50]\n",
    "        t_slice = slice(*t_lims)\n",
    "        \n",
    "        stim_log = exp.stimulus_log\n",
    "        beh_log = exp.behavior_log\n",
    "    \n",
    "        try:\n",
    "            theta = np.asarray(stim_log['bg_theta'])\n",
    "        except:\n",
    "            theta1 = np.asarray(stim_log['open_loop_theta'])\n",
    "            theta1[np.where(np.isnan(theta1))[0]] = 0\n",
    "            theta2 = np.asarray(stim_log['closed_loop_theta'])\n",
    "            theta2[np.where(np.isnan(theta2))[0]] = 0\n",
    "            theta = theta1 + theta2\n",
    "        #theta = np.asarray(stim_log['cl2D_vel'])\n",
    "        stim_t = np.asarray(stim_log.t)\n",
    "\n",
    "        theta_wrapped = np.mod(theta, np.pi * 2) - np.pi\n",
    "        theta_diff = np.zeros_like(theta)\n",
    "        theta_diff[1:] = np.diff(theta)\n",
    "        theta_diff[theta_diff < -0.5] = 0\n",
    "        theta_diff *= 50\n",
    "\n",
    "        pos_theta = np.copy(theta_diff)\n",
    "        pos_theta[pos_theta < 0] = 0\n",
    "\n",
    "        neg_theta = np.copy(theta_diff)\n",
    "        neg_theta[neg_theta > 0] = 0\n",
    "\n",
    "        theta_off = np.zeros_like(theta)\n",
    "        theta_off[1:] = np.diff(theta)\n",
    "        \n",
    "        fs = exp.fn\n",
    "        dt_imaging = 1 / fs\n",
    "        int_fact = 200\n",
    "        t_imaging = np.arange(traces.shape[1])/fs\n",
    "        num_traces, len_rec = np.shape(traces)\n",
    "\n",
    "        # generating regressors\n",
    "        tau_fs = REGRESSOR_TAU_S * fn\n",
    "        kernel = np.exp(-np.arange(1000) / tau_fs)\n",
    "        t_imaging_int = np.arange(traces.shape[1]*int_fact)*dt_imaging/int_fact\n",
    "    \n",
    "        theta_int = interp1d(stim_log.t, theta, bounds_error=False, fill_value=0)(t_imaging_int)\n",
    "        theta_reg = signal.decimate(theta_int, int_fact, ftype=\"fir\")\n",
    "        theta_reg_conv = np.convolve(theta_reg, kernel)[:np.shape(traces)[1]]\n",
    "\n",
    "        theta_wrp_int = interp1d(stim_log.t, theta_wrapped, bounds_error=False, fill_value=0)(t_imaging_int)\n",
    "        theta_wrp_reg = signal.decimate(theta_wrp_int, int_fact, ftype=\"fir\")\n",
    "        theta_wrp_conv = np.convolve(theta_wrp_reg, kernel)[:np.shape(traces)[1]]\n",
    "\n",
    "        theta_diff_int = interp1d(stim_log.t, theta_diff, bounds_error=False, fill_value=0)(t_imaging_int)\n",
    "        theta_diff_reg = signal.decimate(theta_diff_int, int_fact, ftype=\"fir\")\n",
    "        theta_diff_conv = np.convolve(theta_diff_reg, kernel)[:np.shape(traces)[1]]\n",
    "\n",
    "        theta_off_int = interp1d(stim_log.t, theta_off, bounds_error=False, fill_value=0)(t_imaging_int)\n",
    "        theta_off_reg = signal.decimate(theta_off_int, int_fact, ftype=\"fir\") * -1\n",
    "        theta_off_conv = np.convolve(theta_off_reg, kernel)[:np.shape(traces)[1]]\n",
    "        \n",
    "        \n",
    "        stim_t_conv = np.arange(np.shape(theta_wrp_conv)[0]) / 5\n",
    "\n",
    "        ax_anatomy1[i - count + 1].imshow(traces[selected], vmin=-1, vmax=2, extent=[0, 1500, 0, 500])\n",
    "        ax_anatomy1[i - count + 1].axis('off')\n",
    "\n",
    "        theta_traces = np.dot(traces, theta_reg_conv) - num_traces * np.mean(traces, 1) * np.mean(theta_reg_conv)\n",
    "        theta_traces /= (traces.shape[1] - 1) * np.std(traces, 1) * np.std(theta_reg_conv)\n",
    "\n",
    "        theta_wrp_traces = np.dot(traces, theta_wrp_conv) - num_traces * np.mean(traces, 1) * np.mean(theta_wrp_conv)\n",
    "        theta_wrp_traces /= (traces.shape[1] - 1) * np.std(traces, 1) * np.std(theta_wrp_conv)\n",
    "\n",
    "        theta_diff_traces = np.dot(traces, theta_diff_conv) - num_traces * np.mean(traces, 1) * np.mean(theta_diff_conv)\n",
    "        theta_diff_traces /= (traces.shape[1] - 1) * np.std(traces, 1) * np.std(theta_diff_conv)\n",
    "\n",
    "        theta_off_traces = np.dot(traces, theta_off_conv) - num_traces * np.mean(traces, 1) * np.mean(theta_diff_conv)\n",
    "        theta_off_traces /= (traces.shape[1] - 1) * np.std(traces, 1) * np.std(theta_off_conv)\n",
    "        \n",
    "        \n",
    "\n",
    "        ax_anatomy2[i-count,0].scatter(coords[:, 1], coords[:, 2], c=theta_wrp_traces, cmap='coolwarm', s=3, vmin=-1, vmax=1)\n",
    "        ax_anatomy2[i-count,0].spines['right'].set_visible(False)\n",
    "        ax_anatomy2[i-count,0].spines['top'].set_visible(False)\n",
    "        ax_anatomy2[i-count,0].spines['left'].set_visible(False)\n",
    "        ax_anatomy2[i-count,0].spines['bottom'].set_visible(False)\n",
    "        ax_anatomy2[i-count,0].set_xticks([])\n",
    "        ax_anatomy2[i-count,0].set_yticks([])\n",
    "        ax_anatomy2[i-count,0].set_ylabel(fish_id)\n",
    "        \n",
    "        ax_anatomy2[i-count,1].scatter(coords[:, 1], coords[:, 2], c=theta_diff_traces, cmap='coolwarm', s=3, vmin=-1, vmax=1)\n",
    "        ax_anatomy2[i-count,1].axis('off')\n",
    "\n",
    "        ax_anatomy2[i-count,2].scatter(coords[:, 1], coords[:, 2], c=theta_off_traces, cmap='coolwarm', s=3, vmin=-1, vmax=1)\n",
    "        ax_anatomy2[i-count,2].axis('off')\n",
    "        \n",
    "        ax_anatomy2[i-count,3].scatter(coords[selected, 1], coords[selected, 2], c=theta_wrp_traces[selected], cmap='coolwarm', s=3, vmin=-1, vmax=1)\n",
    "        ax_anatomy2[i-count,3].axis('off')\n",
    "        \n",
    "        ax_anatomy2[i-count,4].scatter(coords[selected, 1], coords[selected, 2], c=theta_diff_traces[selected], cmap='coolwarm', s=3, vmin=-1, vmax=1)\n",
    "        ax_anatomy2[i-count,4].axis('off')\n",
    "\n",
    "        ax_anatomy2[i-count,5].scatter(coords[selected, 1], coords[selected, 2], c=theta_off_traces[selected], cmap='coolwarm', s=3, vmin=-1, vmax=1)\n",
    "        ax_anatomy2[i-count,5].axis('off')\n",
    "        \n",
    "    except:\n",
    "        print(\"no selected\")\n",
    "        count += 1\n",
    "\n",
    "ax_anatomy1[0].plot(stim_t_conv, theta_wrp_conv)\n",
    "ax_anatomy1[0].plot(stim_t_conv, theta_diff_conv + 80)\n",
    "ax_anatomy1[0].plot(beh_log.t, beh_log.tail_sum*10 - 80)\n",
    "ax_anatomy1[0].plot(stim_t_conv, theta_off_conv/5 - 200)\n",
    "ax_anatomy1[0].set_xlim(0, stim_t_conv[-1])\n",
    "ax_anatomy1[0].axis('off')\n",
    "        \n",
    "ax_anatomy2[0,0].set_title('Theta position')\n",
    "ax_anatomy2[0,1].set_title('Theta diff')\n",
    "ax_anatomy2[0,2].set_title('Theta off')\n",
    "\n",
    "ax_anatomy2[0,3].set_title('Theta position - selected')\n",
    "ax_anatomy2[0,4].set_title('Theta diff - selected')\n",
    "ax_anatomy2[0,5].set_title('Theta off - selected')\n",
    "\n",
    "file_name = 'theta_regressors_rois_clol.jpg'\n",
    "fig_anatomy2.savefig(master / file_name, dpi=300)\n",
    "\n",
    "file_name = 'theta_regressors_clol.jpg'\n",
    "fig_anatomy1.savefig(master / file_name, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-story",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making one big figure:\n",
    "from lotr.default_vals import REGRESSOR_TAU_S, TURN_BIAS\n",
    "master =  Path(r\"\\\\Funes\\Shared\\experiments\\E0071_lotr\\full_ring\")\n",
    "files_natmov = list(master.glob(\"*/*_f*_natmov\"))\n",
    "files_clol = list(master.glob(\"*/*_f*_clol\"))\n",
    "\n",
    "all_rois_clol = 0\n",
    "num_fish_clol = 0\n",
    "for i in range(len(files_clol)):\n",
    "    path = files_clol[i]\n",
    "    try:\n",
    "        selected = fl.load(path / \"selected.h5\")\n",
    "        traces = fl.load(path / \"filtered_traces.h5\", \"/detr\").T\n",
    "        \n",
    "        if all_rois_clol is 0:\n",
    "            all_rois_clol = traces\n",
    "        else:\n",
    "            all_rois_clol = np.append(all_rois_clol, traces, axis=0)\n",
    "        num_fish_clol += 1\n",
    "    except:\n",
    "        print(\"no selected\")\n",
    "\n",
    "print(num_fish_clol)\n",
    "'''\n",
    "all_rois_natmov = 0\n",
    "num_fish_natmov = 0\n",
    "for i in range(len(files_natmov)):\n",
    "    path = files_natmov[i]\n",
    "    try:\n",
    "        selected = fl.load(path / \"selected.h5\")\n",
    "        traces = fl.load(path / \"filtered_traces.h5\", \"/detr\").T\n",
    "        print(np.shape(traces))\n",
    "        \n",
    "        if all_rois_natmov is 0:\n",
    "            all_rois_natmov = traces\n",
    "        else:\n",
    "            print(i)\n",
    "            all_rois_natmov = np.append(all_rois_natmov, traces, axis=0)\n",
    "        num_fish_natmov += 1\n",
    "    except:\n",
    "        print(\"no selected\")\n",
    "\n",
    "print(num_fish_nclol)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-devil",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(all_rois_clol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-language",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage, cut_tree, to_tree, set_link_color_palette\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-message",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_id_search(tree):\n",
    "    nodes_list = []\n",
    "    if tree.is_leaf():\n",
    "        nodes_list.append(tree.get_id())\n",
    "    else:\n",
    "        nodes_list += cluster_id_search(tree.get_left())\n",
    "        nodes_list += cluster_id_search(tree.get_right())\n",
    "        \n",
    "    return nodes_list\n",
    "\n",
    "def find_trunc_dendro_clusters(linkage_mat, dendro):\n",
    "    tree, branches = to_tree(linkage_mat, rd =True)\n",
    "    ids = np.empty(linkage_mat.shape[0]+1, dtype=int)\n",
    "    \n",
    "    for i, clust in enumerate(dendro[\"leaves\"]):\n",
    "        ids[cluster_id_search(branches[clust])] = i\n",
    "        \n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-greece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering of traces to see if the responses are more motor (fish specific) or visual (similar across fish):\n",
    "\n",
    "fig1 = plt.figure(figsize=(10,7))\n",
    "linked = linkage(all_rois_clol, method='ward')\n",
    "dend = dendrogram(linked)\n",
    "\n",
    "cluster = AgglomerativeClustering(n_clusters=12, affinity='euclidean', linkage='ward')\n",
    "her_clustering = cluster.fit_predict(all_rois_clol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-tobago",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make truncated tree to get clusters ids. \n",
    "# Ugly but necessary to get the same sequence of leaves as the cut.\n",
    "plt.figure(figsize=(0.1, 0.1))  \n",
    "n_clust = 8\n",
    "dendro = dendrogram(linked, n_clust, truncate_mode =\"lastp\")\n",
    "plt.close()\n",
    "cluster_ids = dendro[\"leaves\"]\n",
    "labels = find_trunc_dendro_clusters(linked, dendro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-windows",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanresps = all_rois_clol\n",
    "base_sub_mean = (meanresps.T - np.nanmean(meanresps[:,:8], 1)).T\n",
    "X = base_sub_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-basketball",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import color\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram, cut_tree, set_link_color_palette\n",
    "#import seaborn as sns\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-garlic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shade_plot(stim, ax=None, gamma=1/6, shade_range=(0.6, 0.9)):\n",
    "    if type(stim) == list:  # these would be transitions\n",
    "        _shade_plot(stim, ax=ax, gamma=gamma, shade_range=shade_range)\n",
    "\n",
    "    elif type(stim) == Data:  # fish data\n",
    "        transitions = find_transitions(Data.resampled_stim, Data.time_im_rep)\n",
    "        _shade_plot(transitions, ax=ax, gamma=gamma, shade_range=shade_range)\n",
    "\n",
    "    elif type(stim) == np.ndarray:  # stimulus array\n",
    "        transitions = find_transitions(stim[:,1], stim[:,0])\n",
    "        _shade_plot(transitions, ax=ax, gamma=gamma, shade_range=shade_range)\n",
    "\n",
    "    elif type(stim) == tuple:  # time, lum tuple\n",
    "        transitions = find_transitions(stim[1], stim[0])\n",
    "        _shade_plot(transitions, ax=ax, gamma=gamma, shade_range=shade_range)\n",
    "\n",
    "\n",
    "def _shade_plot(lum_transitions, ax=None, gamma=1/6, shade_range=(0.6, 0.9)):\n",
    "\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    shade = lum_transitions[0][1]\n",
    "    for i in range(len(lum_transitions)-1):\n",
    "        shade = shade + lum_transitions[i][1]\n",
    "        new_shade = shade_range[0] + np.power(np.abs(shade), gamma) * (shade_range[1] - shade_range[0])\n",
    "        ax.axvspan(lum_transitions[i][0], lum_transitions[i+1][0], color=(new_shade, )*3)\n",
    "        \n",
    "\n",
    "def _find_thr(linked, n_clust):\n",
    "    interval = [0, 2000]\n",
    "    new_height = np.mean(interval)\n",
    "    clust = 0\n",
    "    n_clust = n_clust\n",
    "    while clust != n_clust:\n",
    "        new_height = np.mean(interval)\n",
    "        clust = cut_tree(linked, height=new_height).max()\n",
    "        if clust > n_clust:\n",
    "            interval[0] = new_height\n",
    "        elif clust < n_clust:\n",
    "            interval[1] = new_height\n",
    "\n",
    "\n",
    "    return new_height\n",
    "\n",
    "\n",
    "def find_plot_thr(linked, n_clust):\n",
    "    min_thr = _find_thr(linked, n_clust - 1)\n",
    "    return min_thr  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-course",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters_dendro(traces, stim, linkage_mat, labels, dendrolims=(900, 30),\n",
    "                         thr=None, f_lim=1.5, gamma=1):\n",
    "    fig_clust, ax = plt.subplots(3, 1, figsize=(10, 10))\n",
    "    hexac = cluster_cols()\n",
    "\n",
    "    n_clust = labels.max() + 1\n",
    "\n",
    "    ##################\n",
    "    ### Dendrogram ###\n",
    "    # Compute and plot first dendrogram.\n",
    "    if thr is None:\n",
    "        thr = find_plot_thr(linkage_mat, n_clust)\n",
    "\n",
    "    set_link_color_palette(hexac)\n",
    "    ax_traces = plt.subplot2grid((2, 2), (0, 0))\n",
    "    ax_clusters = plt.subplot2grid((2, 2), (0, 1))\n",
    "    ax_dendro = plt.subplot2grid((2, 2), (1, 0), colspan=2)\n",
    "\n",
    "    #ax_dendro = ax[2]\n",
    "    #ax_traces = ax[1]\n",
    "    #ax_clusters = ax[0]\n",
    "    \n",
    "    panel_dendro = dendrogram(linkage_mat,\n",
    "                              color_threshold=thr,\n",
    "                              #orientation='left',\n",
    "                              distance_sort='descending',\n",
    "                              show_leaf_counts=False,\n",
    "                              no_labels=True,\n",
    "                              above_threshold_color='#%02x%02x%02x' % (\n",
    "                              120, 120, 120))\n",
    "    \n",
    "    ax_dendro.axhline(thr, linewidth=0.7, color=\"k\")\n",
    "    ax_dendro.axis(\"off\")\n",
    "\n",
    "    # Plot traces matrix.\n",
    "    im = ax_traces.imshow(traces[panel_dendro[\"leaves\"], :],\n",
    "                         aspect='auto', origin='lower', cmap=cm.RdBu_r,\n",
    "                         vmin=-f_lim, vmax=f_lim)\n",
    "    ax_traces.axes.spines['left'].set_visible(False)\n",
    "    ax_traces.set_yticks([])\n",
    "\n",
    "    # Time bar:\n",
    "    dt = stim[1, 0]\n",
    "    barlength = 10\n",
    "    bounds = np.array([traces.shape[1] - barlength / dt,\n",
    "                       traces.shape[1]])\n",
    "\n",
    "    ##################\n",
    "    # Cluster sizes ##\n",
    "    # Calculate size of each defined cluster to put colored labels on the side.\n",
    "    # Find indervals spanned by each cluster in the sorted traces matrix.\n",
    "    # Add percentages spanned by each cluster.\n",
    "    sizes = np.cumsum(np.array([np.sum(labels == i) for i in range(np.max(labels) + 1)]))\n",
    "    intervals = np.insert(sizes, 0, 0)\n",
    "\n",
    "    ##################\n",
    "    # Cluster means ##\n",
    "\n",
    "    for i in range(n_clust):\n",
    "        ax_clusters.plot(np.nanmean(traces[labels == i, :], 0) +\n",
    "                      i * 5, label=i, color=hexac[i])\n",
    "    ax_clusters.axes.spines['left'].set_visible(False)\n",
    "    ax_clusters.set_yticks([])\n",
    "\n",
    "    barlength = 10\n",
    "    ax_traces.axis(\"off\")\n",
    "    ax_clusters.axis(\"off\")\n",
    "\n",
    "    return fig_clust, ax_clusters\n",
    "\n",
    "def cluster_cols():\n",
    "    # color_list = [\"lightblue\", \"lightcoral\", \"orange\", \"springgreen\", \"deepskyblue\", \"mediumpurple\",\"gold\", \"cyan\", \"crimson\", \"deeppink\", \"lawngreen\", \"darkviolet\", \"orchid\", \"limegreen\", \"seagreen\", \"chocolate\", \"blue\", \"navy\"]\n",
    "    color_list = [\"#cc566a\", \"#cd6c39\", \"#a39440\", \"#64ac48\", \"#4aac8d\", \"#688bcd\", \"#8562cc\", \"#c361aa\"]\n",
    "    # color_list = [\"#ff5c67\", \"#af0006\", \"#ffa468\", \"#8c5f00\", \"#e4a400\", \"#d5c86f\", \"#939400\", \"#a7d380\", \"#138b00\", \"#42e087\", \"#00a86d\", \"#81c7a8\", \"#019a82\", \"#1eaaff\", \"#0268bb\", \"#5951d7\", \"#6b4570\", \"#ad20aa\", \"#ffa1e2\", \"#ff4a94\"]\n",
    "    return color_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-carter",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim = np.asarray([[1, 2, 3, 4, 5, 6, 7], [1, 2, 3, 4, 5, 6, 7]])\n",
    "fig_clust, ax_clust = plot_clusters_dendro(all_rois_clol, stim, linked, labels)#, dendrolims=(940, 0))\n",
    "\n",
    "f = files_clol[0]\n",
    "exp = LotrExperiment(path=f)\n",
    "    \n",
    "plt.show()\n",
    "file_name = 'hierarchical_clustering_220531.jpg'\n",
    "fig_clust.savefig(str(master/file_name), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-walnut",
   "metadata": {},
   "outputs": [],
   "source": [
    "### getting the indices for each fish:\n",
    "num_fish = 7\n",
    "fish_inds = np.zeros(num_fish)\n",
    "print(num_fish)\n",
    "num_rois = np.zeros(num_fish)\n",
    "count = 0\n",
    "for i in range(len(files_clol)):\n",
    "    f = files_clol[i]\n",
    "    traces = fl.load(f / \"filtered_traces.h5\", \"/detr\").T\n",
    "    num_traces = np.shape(traces)[0]\n",
    "    try:\n",
    "        selected = fl.load(f / \"selected.h5\")\n",
    "        num_rois[i-count] = num_traces \n",
    "        fish_inds[i-count] = i\n",
    "    except:\n",
    "        count += 1\n",
    "print(num_rois)\n",
    "print(fish_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-affect",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-focus",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind2 = np.cumsum(num_rois).astype(int)\n",
    "ind2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rois= num_rois.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-yahoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind1 = np.zeros(num_fish+1, dtype=int)\n",
    "for i in range(num_fish):\n",
    "    ind1[i+1] = ind2[i]\n",
    "ind1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-argument",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(labels)\n",
    "np.shape(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-factor",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_row = 3\n",
    "num_col = 3\n",
    "fig1, ax1 = plt.subplots(num_row, num_col, figsize=(8, 8))\n",
    "\n",
    "for i in range(num_row*num_row):\n",
    "    r = i // num_row\n",
    "    c = np.mod(i, num_row)\n",
    "    \n",
    "    try:\n",
    "        path = files_clol[fish_inds[i].astype(int)]\n",
    "        coords = fl.load(path / \"data_from_suite2p_unfiltered.h5\", \"/coords\")\n",
    "        col_hrc = labels[ind1[i]:ind2[i]]\n",
    "\n",
    "        ax1[r, c].scatter(coords[:, 1], coords[:, 2], c=col_hrc, cmap='rainbow', s=3, vmin=0, vmax=7)\n",
    "        ax1[r, c].axis('off')\n",
    "    except:\n",
    "        print(i)\n",
    "        ax1[r, c].axis('off')\n",
    "\n",
    "    \n",
    "plt.show()\n",
    "file_name = 'clusters_hrc_rois_220531.jpg'\n",
    "fig1.savefig(str(master/file_name), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-automation",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_row = 3\n",
    "num_col = 3\n",
    "fig1, ax1 = plt.subplots(num_row, num_col, figsize=(8, 8))\n",
    "\n",
    "for i in range(num_row*num_row):\n",
    "    r = i // num_row\n",
    "    c = np.mod(i, num_row)\n",
    "    \n",
    "    try:\n",
    "        path = files_clol[fish_inds[i].astype(int)]\n",
    "        coords = fl.load(path / \"data_from_suite2p_unfiltered.h5\", \"/coords\")\n",
    "        selected = fl.load(path / \"selected.h5\")\n",
    "        col_hrc = labels[ind1[i]:ind2[i]]\n",
    "        \n",
    "        ax1[r, c].scatter(coords[:, 1], coords[:, 2], c='gray', s=3)\n",
    "        ax1[r, c].scatter(coords[selected, 1], coords[selected, 2], c=col_hrc[selected], cmap='rainbow', s=3, vmin=0, vmax=7)\n",
    "        ax1[r, c].axis('off')\n",
    "    except:\n",
    "        ax1[r, c].axis('off')\n",
    "\n",
    "    \n",
    "plt.show()\n",
    "file_name = 'clusters_hrc_rois_selected_220531.jpg'\n",
    "fig1.savefig(str(master/file_name), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-database",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-charge",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

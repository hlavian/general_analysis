{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from split_dataset import SplitDataset\n",
    "from fimpy.pipeline.alignment import align_2p_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = Path(r\"Z:\\Anja & Hagar\")\n",
    "all_fish = list(master.glob(\"*f[0-9]*\"))\n",
    "fish_dir = all_fish[-2]\n",
    "print(all_fish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = \"anatomy\\original\"\n",
    "source_dir = \"original\"\n",
    "\n",
    "frames_per_plane = None\n",
    "aligned_dir = \"aligned\"\n",
    "force_realign = False\n",
    "force_remake_tifs = False\n",
    "force_remake_corr = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_realign = False\n",
    "for f in [fish_dir]:\n",
    "    print(f)\n",
    "    if not(f/'aligned').exists() or force_realign:\n",
    "        align_2p_volume(SplitDataset(f / source_dir), output_dir=str(f), across_planes=False)\n",
    "    else:\n",
    "        print(\"Already aligned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "align_2p_volume(SplitDataset(fish_dir / source_dir), output_dir=str(fish_dir), across_planes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = SplitDataset(fish_dir / \"aligned\")\n",
    "stack = ds[:, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stack.max(), stack.mean())\n",
    "mean = stack.mean(0)\n",
    "print(np.shape(mean))\n",
    "skio.imsave(str(fish_dir / \"anatomy.tif\"), mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = 0\n",
    "stack = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = SplitDataset(fish_dir / source_dir)\n",
    "stack = ds[:, :, :, :]\n",
    "print(stack.max(), stack.mean())\n",
    "mean = stack.mean(0)\n",
    "print(np.shape(mean))\n",
    "skio.imsave(str(fish_dir / \"anatomy_original.tif\"), mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = skio.imread(str(fish_dir /  \"anatomy.tif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "align_2p_volume(SplitDataset(fish_dir / source_dir), output_dir=str(fish_dir), reference=mean, across_planes=False)\n",
    "ds = SplitDataset(fish_dir / \"aligned\")\n",
    "stack = ds[:, :, :, :]\n",
    "print(stack.max(), stack.mean())\n",
    "mean = stack.mean(0)\n",
    "print(np.shape(mean))\n",
    "skio.imsave(str(fish_dir / \"anatomy2.tif\"), mean.astype(np.uint16))\n",
    "ds = 0\n",
    "stack = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#anatomy = skio.imread(str(fish_dir / \"anatomy1.tif\"))\n",
    "#anatomy2 = anatomy.T\n",
    "#print(np.shape(anatomy2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_realign = True\n",
    "force_remake_tifs = False \n",
    "\n",
    "for i in range(2, 5):\n",
    "    \n",
    "    anatomy_file = \"anatomy\" + str(i) + \".tif\"\n",
    "    \n",
    "    # Create anatomy tif file:\n",
    "    if not (fish_dir / anatomy_file).exists() or force_remake_tifs:\n",
    "        print(\"Saving anatomy...\")\n",
    "        ds = SplitDataset(fish_dir / \"aligned\")\n",
    "        stack = ds[:, :, :, :]\n",
    "        print(stack.max())\n",
    "        mean = stack.mean(0)\n",
    "\n",
    "        skio.imsave(str(fish_dir / anatomy_file), mean.astype(np.uint16))\n",
    "        stack = 0\n",
    "        \n",
    "    # Align:\n",
    "    if not (fish_dir / aligned_dir).exists() or force_realign:\n",
    "        print(\"Aligning...\")\n",
    "\n",
    "        anatomy = skio.imread(str(fish_dir / anatomy_file))\n",
    "        #anatomy = anatomy.T\n",
    "        align_2p_volume(SplitDataset(fish_dir / source_dir), output_dir=str(fish_dir), reference=anatomy, across_planes=False)\n",
    "    else:\n",
    "        print(\"Already aligned\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (fish_dir / \"corrmap.tif\").exists():\n",
    "    print(\"Saving correlation map\")\n",
    "    ds = SplitDataset(fish_dir / \"aligned\")\n",
    "    corr_map = correlation_map(ds)[:, :, :]\n",
    "    skio.imsave(str(fish_dir / \"corrmap.tif\"), corr_map.astype(np.float))\n",
    "    \n",
    "ds = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flammkuchen as fl\n",
    "from fimpy.pipeline.roi_extraction import extract_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting traces: \n",
    "# master = Path(r\"C:\\Users\\lavian\\Desktop\\data\\e0040_V13\")\n",
    "master = Path(r\"\\\\Funes\\Shared\\experiments\\E0040_motions_cardinal\\v13_cw_ccw\\2p\\habenula\\fixed\")\n",
    "master = Path(r\"C:\\Users\\lavian\\Desktop\\data\\e0040_V13\\rf\\fixed\")\n",
    "all_fish = list(master.glob(\"*f[0-9]*\"))\n",
    "fish_dir = all_fish[5]\n",
    "print(fish_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_rois = str(fish_dir/'merged_rois.h5')\n",
    "dir_aligned = str(fish_dir / \"aligned\")\n",
    "aligned = SplitDataset(dir_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois_arr = fl.load(dir_rois)['stack'] \n",
    "rois_arr = rois_arr.astype(int) - 1\n",
    "traces = extract_traces(aligned, rois_arr)\n",
    "np.shape(rois_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir_rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e649c927-f03d-461f-b28a-86915cb6c277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib widget\n",
    "\n",
    "import numpy as np\n",
    "from split_dataset import SplitDataset\n",
    "from pathlib import Path\n",
    "import flammkuchen as fl\n",
    "import matplotlib.pyplot as plt \n",
    "from fimpylab.core.lightsheet_experiment import LightsheetExperiment\n",
    "from bouterin.plots.stimulus_log_plot import get_paint_function\n",
    "\n",
    "from bouter.utilities import reliability \n",
    "from skimage.filters import threshold_otsu\n",
    "import xarray as xr\n",
    "from scipy.signal import detrend \n",
    "\n",
    "from motions.utilities import stim_vel_dir_dataframe, quantize_directions\n",
    "import tifffile as tiff\n",
    "from scipy.signal import argrelextrema\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06033893-e2e2-438a-bf1f-8428c8d619b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_path =  Path(r\"Z:\\Hagar\\E0040\\ablations\\pre\\v31\")\n",
    "fish_list = list(master_path.glob(\"*f*\"))\n",
    "thresh = 0.15\n",
    "n_dir=8\n",
    "n_sessions = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d606bd70-cd66-46ed-8284-18ac6eabde35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in fish_list:\n",
    "    print(path)\n",
    "    traces = fl.load(path / \"filtered_traces.h5\", \"/detr\")   \n",
    "    exp = LightsheetExperiment(path)\n",
    "    fs = int(exp.fn)\n",
    "    \n",
    "    suite2p_brain = fl.load(path / \"data_from_suite2p_cells_brain.h5\")\n",
    "    in_brain_idx = suite2p_brain['coords_idx']\n",
    "    traces = traces[:, in_brain_idx]\n",
    "\n",
    "    t = np.arange(np.shape(traces)[1]) / fs\n",
    "    len_rec, num_traces = np.shape(traces)\n",
    "    print(\"num_traces: \", num_traces)\n",
    "    print(\"len_rec: \", len_rec)\n",
    "    print(\"sampling rate: \", fs)\n",
    "    \n",
    "    try:\n",
    "        regs = fl.load(path / \"sensory_regressors.h5\", \"/regressors\")[0]\n",
    "        right = np.asarray(regs.iloc[:, 0])\n",
    "        left = np.asarray(regs.iloc[:, 4])\n",
    "    except:\n",
    "        regs = fl.load(path / \"sensory_regressors.h5\", \"/regressors\")\n",
    "        right = np.asarray(regs.iloc[:, 0])\n",
    "        left = np.asarray(regs.iloc[:, 4])\n",
    "        \n",
    "    num_traces = np.shape(traces)[1]\n",
    "\n",
    "    right_corr = np.zeros((num_traces))\n",
    "    left_corr = np.zeros((num_traces))\n",
    "    for i in range(num_traces):\n",
    "        right_corr[i] = np.corrcoef(right, traces[:, i])[0,1]\n",
    "        left_corr[i] = np.corrcoef(left, traces[:, i])[0,1]\n",
    "        \n",
    "    right_tuned = np.where(np.abs(right_corr) > thresh)[0]\n",
    "    print(np.shape(right_tuned))\n",
    "    n_right_tuned = np.shape(right_tuned)[0]\n",
    "\n",
    "    left_tuned = np.where(np.abs(left_corr) > thresh)[0]\n",
    "    print(np.shape(left_tuned))\n",
    "    n_left_tuned = np.shape(left_tuned)[0]\n",
    "    \n",
    "    left_traces = traces[:, left_tuned].T\n",
    "    right_traces = traces[:, right_tuned].T\n",
    "    \n",
    "    #### Getting a list of stimuli order: 0=right, 7=right-up\n",
    "    pause_duration = int(exp['stimulus']['protocol']['E0040_motions_cardinal']['v31_8dir_plus_hd']['pause_duration']) * fs\n",
    "    stim_duration = int(exp['stimulus']['protocol']['E0040_motions_cardinal']['v31_8dir_plus_hd']['moving_duration']) * fs\n",
    "\n",
    "    left_diff = np.diff(left)\n",
    "    right_diff = np.diff(right)\n",
    "\n",
    "    left_start = find_peaks(left_diff, height=0.1)[0] - stim_duration - pause_duration\n",
    "    left_end = find_peaks(left_diff, height=0.1)[0] + stim_duration + pause_duration\n",
    "    right_start = find_peaks(right_diff, height=0.1)[0] - stim_duration - pause_duration\n",
    "    right_end = find_peaks(right_diff, height=0.1)[0] + stim_duration + pause_duration\n",
    "    \n",
    "    num_left_trials = np.shape(left_start)[0]\n",
    "    num_right_trials = np.shape(right_start)[0]\n",
    "    len_segment = (pause_duration + stim_duration) * 2\n",
    "\n",
    "    left_trials = np.zeros((n_dir, n_left_tuned, n_sessions, len_segment))\n",
    "    right_trials = np.zeros((n_dir, n_right_tuned, n_sessions, len_segment))\n",
    "    \n",
    "    regs_array = np.asarray(regs)\n",
    "    curr_session = np.zeros((n_dir), dtype=int)\n",
    "    for i in range(num_left_trials):\n",
    "        t1 = left_start[i]\n",
    "        t2 = t1 + stim_duration\n",
    "\n",
    "        curr_seg = np.nanmean(regs_array[t1:t2], axis=0)\n",
    "\n",
    "        try:\n",
    "            curr_dir = np.where(curr_seg > 0.1)[0][0]\n",
    "\n",
    "            t1 = left_start[i]\n",
    "            t2 = t1 + len_segment\n",
    "\n",
    "            if curr_session[curr_dir] < n_sessions:\n",
    "                left_trials[curr_dir, :, curr_session[curr_dir], :] = left_traces[:, t1:t2]\n",
    "                curr_session[curr_dir] += 1\n",
    "        except:\n",
    "            print(\"Stupid trial\")\n",
    "\n",
    "    left_trials[left_trials == 0] = 'nan'\n",
    "    \n",
    "    curr_session = np.zeros((n_dir), dtype=int)\n",
    "    for i in range(num_right_trials):\n",
    "        t1 = right_start[i]\n",
    "        t2 = t1 + stim_duration\n",
    "        try:\n",
    "            curr_seg = np.nanmean(regs_array[t1:t2], axis=0)\n",
    "            curr_dir = np.where(curr_seg > 0.1)[0][0]\n",
    "\n",
    "            t1 = right_start[i]\n",
    "            t2 = t1 + len_segment\n",
    "\n",
    "\n",
    "            if curr_session[curr_dir] < n_sessions:\n",
    "                right_trials[curr_dir, :, curr_session[curr_dir], :] = right_traces[:, t1:t2]\n",
    "                curr_session[curr_dir] += 1\n",
    "        except:\n",
    "            print(\"Stupid trial\")\n",
    "\n",
    "    right_trials[right_trials == 0] = 'nan'\n",
    "    \n",
    "    ####### Concatenate average responses and cluster\n",
    "    left_trials_concat = np.zeros((n_left_tuned, len_segment * n_dir))\n",
    "\n",
    "    for i in range(n_dir):\n",
    "        lef_trials_avg = np.nanmean(left_trials[i], axis=1)\n",
    "        t1 = i * len_segment\n",
    "        t2 = t1 + len_segment\n",
    "        left_trials_concat[:, t1:t2] = lef_trials_avg\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    right_trials_concat = np.zeros((n_right_tuned, len_segment * n_dir))\n",
    "\n",
    "    for i in range(n_dir):\n",
    "        right_trials_avg = np.nanmean(right_trials[i], axis=1)\n",
    "        t1 = i * len_segment\n",
    "        t2 = t1 + len_segment\n",
    "        right_trials_concat[:, t1:t2] = right_trials_avg\n",
    "\n",
    "    d = {\n",
    "        'concat_reordered_left_tuned_avg': left_trials_concat,\n",
    "         'concat_reordered_right_tuned_avg': right_trials_concat,\n",
    "        'reordered_trials_left_tuned': left_trials,\n",
    "        'reordered_trials_right_tuned': right_trials,\n",
    "    }\n",
    "    fl.save(path / 'reordered_traces.h5', d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccd0eb9-7abc-4d80-ad57-48944d87fc1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

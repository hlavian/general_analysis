{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import flammkuchen as fl\n",
    "from split_dataset import SplitDataset\n",
    "from fimpylab.core.twop_experiment import TwoPExperiment\n",
    "from bouter import Experiment\n",
    "from fimpy.pipeline.general import calc_f0, dff\n",
    "from motions.utilities import stim_vel_dir_dataframe, quantize_directions\n",
    "from scipy.interpolate import interp1d \n",
    "from scipy.signal import convolve2d\n",
    "import colorspacious\n",
    "import napari\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sensory regressors. requires old bouter stimulus_param_log.\n",
    "def make_sensory_regressors(exp, n_dirs=8, upsampling=5, sampling=1/2):\n",
    "    stim = stim_vel_dir_dataframe(exp)\n",
    "    bin_centres, dir_bins = quantize_directions(stim.theta)\n",
    "    ind_regs = np.zeros((n_dirs, len(stim)))\n",
    "    for i_dir in range(n_dirs):\n",
    "        ind_regs[i_dir, :] = (np.abs(dir_bins - i_dir) < 0.1) & (stim.vel > 0.1)  \n",
    "\n",
    "    dt_upsampled = sampling / upsampling\n",
    "    t_imaging_up = np.arange(0, stim.t.values[-1], dt_upsampled)\n",
    "    reg_up = interp1d(stim.t.values, ind_regs, axis=1, fill_value=\"extrapolate\")(\n",
    "        t_imaging_up\n",
    "    )\n",
    "    \n",
    "    # 6s kernel\n",
    "    u_steps = t_imaging_up.shape[0]\n",
    "    u_time = np.arange(u_steps) * dt_upsampled\n",
    "    decay = np.exp(-u_time / (1.5 / np.log(2)))\n",
    "    kernel = decay / np.sum(decay)\n",
    "    \n",
    "    convolved = convolve2d(reg_up, kernel[None, :])[:, 0:u_steps]\n",
    "    reg_sensory = convolved[:, ::upsampling]\n",
    "\n",
    "    return pd.DataFrame(reg_sensory.T, columns=[f\"motion_{i}\" for i in range(n_dirs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the frames to calculate the baseline.\n",
    "def no_regressor_frames(regressors, threshold=0.01):\n",
    "    return np.where(np.all(regressors.values < threshold, axis=1))[0]\n",
    "\n",
    "# calculate the baseline, plane-wise\n",
    "def calc_f0(stack, frames):\n",
    "    fr_mean = None\n",
    "    for i_frame in frames:\n",
    "        sf = stack[int(i_frame), :, :]\n",
    "        if fr_mean is None:\n",
    "            fr_mean = sf\n",
    "        else:\n",
    "            fr_mean += sf\n",
    "    return fr_mean / len(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate directional tuning from dF/F traces, px-wise\n",
    "def get_tuning_map(img, sens_regs, n_dirs=8):\n",
    "    traces = img.reshape(img.shape[0], -1)\n",
    "\n",
    "    n_t = sens_regs.shape[0]\n",
    "    reg = sens_regs.values.T @ traces[:n_t, :]\n",
    "    reg = reg.reshape(reg.shape[0], img.shape[-1], img.shape[-1])\n",
    "    \n",
    "    # tuning vector\n",
    "    bin_centers, bins = quantize_directions([0], n_dirs)\n",
    "    vectors = np.stack([np.cos(bin_centers), np.sin(bin_centers)], 0)\n",
    "    reg_vectors = np.reshape(\n",
    "        vectors @ np.reshape(reg[:, :, :], (n_dirs, -1)),\n",
    "        (2,) + reg.shape[1:],\n",
    "    )\n",
    "    angle = np.arctan2(reg_vectors[1], reg_vectors[0])\n",
    "    amp = np.sqrt(np.sum(reg_vectors ** 2, 0))\n",
    "\n",
    "    return amp, angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a color map\n",
    "\n",
    "def JCh_to_RGB255(x):\n",
    "    output = np.clip(colorspacious.cspace_convert(x, \"JCh\", \"sRGB1\"), 0, 1)\n",
    "    return (output * 255).astype(np.uint8)\n",
    "\n",
    "def color_stack(\n",
    "        amp,\n",
    "        angle,\n",
    "        hueshift=2.5,\n",
    "        amp_percentile=80,\n",
    "        maxsat=50,\n",
    "        lightness_min=100,\n",
    "        lightness_delta=-40,\n",
    "        max_amp=None\n",
    "    ):\n",
    "    output_lch = np.empty(amp.shape + (3,))\n",
    "    \n",
    "    if max_amp is None:\n",
    "        maxamp = np.percentile(amp, amp_percentile)\n",
    "    else:\n",
    "        maxamp = max_amp\n",
    "\n",
    "    output_lch[:, :, 0] = (\n",
    "            lightness_min + (np.clip(amp / maxamp, 0, 1)) * lightness_delta\n",
    "    )\n",
    "    output_lch[:, :, 1] = (np.clip(amp / maxamp, 0, 1)) * maxsat\n",
    "    output_lch[:, :, 2] = (angle + hueshift) * 180 / np.pi\n",
    "\n",
    "    return JCh_to_RGB255(output_lch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master =  Path(r\"\\\\Funes\\Shared\\experiments\\E0040_motions_cardinal\\v13_cw_ccw\\2p\\ipn\\itpr1b - fixed\")\n",
    "fishes = list(master.glob(\"*_f*\"))\n",
    "fish = fishes[0]\n",
    "\n",
    "aligned = SplitDataset(fish / \"aligned\")\n",
    "behavior_path = fish / \"behavior\"\n",
    "exp_list = behavior_path.glob(\"*.json\")\n",
    "#exp_list = behavior_path.glob(\"*.json\")[:aligned.shape[1]]\n",
    "                                           \n",
    "sampling = 1/2\n",
    "time = np.linspace(0, aligned.shape[0]*sampling, aligned.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of sensory regressors for each plane\n",
    "\n",
    "reg_list = [make_sensory_regressors(Experiment(exp)) for exp in exp_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(reg_list))\n",
    "print(np.shape(reg_list[0]))\n",
    "aligned.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the baseline image for each plane\n",
    "\n",
    "frame_list = [no_regressor_frames(reg) for reg in reg_list]\n",
    "#meta_data = json.load(open(fish.glob(\"*metadata.json*\")))\n",
    "#num_planes = metadata[\"shape_full\"][1]\n",
    "#print(num_planes)\n",
    "f0_stack = np.empty((aligned.shape[1], aligned.shape[-1], aligned.shape[-1]))\n",
    "for i, frames in enumerate(frame_list):\n",
    "    #print(i)\n",
    "    try:\n",
    "        f0 = calc_f0(aligned[:,i,:,:], frames)\n",
    "        f0_stack[i,:,:] = f0\n",
    "    except:\n",
    "        print(\"S\")   \n",
    "    \n",
    "# will created a dff split-dataset folder\n",
    "stack = dff(aligned, f0_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(aligned))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate tuning\n",
    "all_amp_percentile = np.zeros((np.shape(aligned)[1]))\n",
    "amps = []\n",
    "angles = []\n",
    "for i in range(aligned.shape[1]):\n",
    "    img = stack[:,i,:,:]\n",
    "    amp, angle = get_tuning_map(img, reg_list[i])\n",
    "    amps.append(amp)\n",
    "    angles.append(angle)\n",
    "    all_amp_percentile[i] = np.percentile(amp, 80)\n",
    "\n",
    "df = pd.DataFrame(list(zip(amps, angles)), columns=[\"amp\", \"angle\"])\n",
    "max_amp = np.max(all_amp_percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fl.save(fish + \"/tuning.h5\", df)\n",
    "max_amp = np.percentile(amps, 80)\n",
    "max_amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a color map from the amplitude/angle\n",
    "\n",
    "pctl = 90\n",
    "\n",
    "color_maps = []\n",
    "for i in range(stack.shape[1]):\n",
    "    amp = df.loc[i, \"amp\"]\n",
    "    angle = df.loc[i, \"angle\"]\n",
    "    color_map = color_stack(np.nan_to_num(amp), np.nan_to_num(angle), amp_percentile=pctl) #default percentile was 80\n",
    "    color_maps.append(color_map)\n",
    "    \n",
    "color_maps = np.array(color_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl.save(fish / \"tuning_map_{}.h5\".format(pctl), color_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with napari.gui_qt():\n",
    "#    v = napari.view_image(color_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_row = 7\n",
    "n_col = 7\n",
    "fig, ax = plt.subplots(n_row, n_col, figsize=(12,12))\n",
    "for i in range(n_row*n_col):\n",
    "    r = i // n_row\n",
    "    c = np.mod(i, n_col)\n",
    "    tmp_plane = color_maps[i]\n",
    "    #print(np.min(tmp_plane), np.max(tmp_plane))\n",
    "    tmp_plane = np.rot90(tmp_plane, k=1, axes=(1, 0))\n",
    "    ax[r, c].imshow(tmp_plane,  vmin=0, vmax=255)\n",
    "    ax[r, c].axis('off')\n",
    "plt.show()\n",
    "file_name = \"tuning_plot_all_planes_210901.jpg\"\n",
    "fig.savefig(str(fish/file_name), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check the regressors made by make_sensory_regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Experiment(exp_list[0])\n",
    "n_dirs=8\n",
    "upsampling=5\n",
    "sampling=1/3\n",
    "\n",
    "'''def'''\n",
    "stim = stim_vel_dir_dataframe(exp)\n",
    "bin_centres, dir_bins = quantize_directions(stim.theta)\n",
    "ind_regs = np.zeros((n_dirs, len(stim)))\n",
    "for i_dir in range(n_dirs):\n",
    "    ind_regs[i_dir, :] = (np.abs(dir_bins - i_dir) < 0.1) & (stim.vel > 0.1)  \n",
    "\n",
    "dt_upsampled = sampling / upsampling\n",
    "t_imaging_up = np.arange(0, stim.t.values[-1], dt_upsampled)\n",
    "reg_up = interp1d(stim.t.values, ind_regs, axis=1, fill_value=\"extrapolate\")(\n",
    "    t_imaging_up\n",
    ")\n",
    "\n",
    "u_steps = t_imaging_up.shape[0]\n",
    "u_time = np.arange(u_steps) * dt_upsampled\n",
    "decay = np.exp(-u_time / (1.5 / np.log(2)))\n",
    "kernel = decay / np.sum(decay)\n",
    "convolved = convolve2d(reg_up, kernel[None, :])[:, 0:u_steps]\n",
    "reg_sensory = convolved[:, ::upsampling]\n",
    "'''return'''\n",
    "sens_regs = pd.DataFrame(reg_sensory.T, columns=[f\"motion_{i}\" for i in range(n_dirs)])\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(3,1, figsize=(8,4), constrained_layout=True)\n",
    "ax[0].plot(stim[\"t\"], stim[\"theta\"])\n",
    "for i in range(n_dirs):\n",
    "    ax[1].plot(ind_regs[i,:])\n",
    "    ax[2].plot(sens_regs.values.T[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
